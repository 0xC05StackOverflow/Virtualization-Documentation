---
title: Getting Started with Swarm Mode
description: Intializing a swarm cluster, creating an overlay network, and attaching a service to the network.
keywords: docker, containers, swarm, orchestration
author: kallie-b
ms.date: 02/9/2017
ms.topic: article
ms.prod: windows-containers
ms.service: windows-containers
ms.assetid: 5ceb9626-7c48-4d42-81f8-9c936595ad85
---

# Getting Started with Swarm Mode 

**Important Note:** *Currently, swarm mode and overlay networking support are available only to [Windows Insiders](https://insider.windows.com/) as part of the upcoming Windows 10, Creators Update. Support for further Windows platforms coming soon.*

## What is “swarm mode”?
Swarm mode is a Docker feature that provides built in container orchestration capabilities, including native clustering of Docker hosts and scheduling of container workloads. A group of Docker hosts form a “swarm” cluster when their Docker engines are running together in “swarm mode.” For additional context on swarm mode, refer to [Docker's main documentation site](https://docs.docker.com/engine/swarm/).

## Manager nodes and worker nodes
A swarm is composed of two types of container hosts: *manager nodes*, and *worker nodes*. Every swarm is initialized via a manager node, and all Docker CLI commands for controlling and monitoring a swarm must be executed from one of its manager nodes. Manager nodes can be thought of as “keepers” of the Swarm state—together, they form a consensus group that maintains awareness of the state of services running on the swarm, and it’s their job to ensure that the swarm’s actual state always matches its intended state, as defined by the developer or admin. 

>	**Note:** Any given swarm can have multiple manager nodes, but it must always have *at least one*. 

Worker nodes are orchestrated by Docker swarm via manager nodes. To join a swarm, a worker node must use a “join token” that was generated by the manager node when the swarm was initialized. Worker nodes simply receive and execute tasks from manager nodes, and so they require (and possess) no awareness of the swarm state.

## Swarm mode system requirements

One computer system (physical or virtual) running **Windows 10 Creators Update** (available for members of the [Windows Insiders](https://insider.windows.com/) program), setup as a container host (see the topic, [Windows Containers on Windows 10](https://docs.microsoft.com/en-us/virtualization/windowscontainers/quick-start/quick-start-windows-10) for more details on how to get started with Docker containers on Windows 10)

**Docker Engine v1.13.0 or later**

Open ports: The following ports must be available on each host. On some systems, these ports are open by default.
- TCP port 2377 for cluster management communications
- TCP and UDP port 7946 for communication among nodes
- TCP and UDP port 4789 for overlay network traffic

## Initializing a Swarm cluster
To initialize a swarm, simply run the following command from one of your container hosts (replacing <HOSTIPADDRESS> with the local IPv4 address of your host machine):

```none
# Initialize a swarm 
C:\> docker swarm init --advertise-addr=<HOSTIPADDRESS> --listen-addr <HOSTIPADDRESS>:2377
```
When this command is run from a given container host, the Docker engine on that host begins running in swarm mode as a manager node.

## Adding nodes to a swarm

> **Note:** Multiple nodes are *not* required to leverage swarm mode and overlay networking mode features. All swarm/overlay features can be used with a single host running in swarm mode (i.e. a manager node, put into swarm mode with the `docker swarm init` command).

### Adding workers to a swarm
Once a swarm has been initialized from a manager node, other hosts can be added to the swarm as workers with another simple command:

```none
C:\> docker swarm join --token <WORKERJOINTOKEN> <MANAGERIPADDRESS>
```

Here, <MANAGERIPADDRESS> is the local IP address of a swarm manager node, and <WORKERJOINTOKEN> is the worker join-token provided as output by the `docker swarm init` command that was run from the manager node. The join-token can also be obtained by running one of the following commands from the manager node after the swarm has been initialized:

```none
# Get the full command required to join a worker node to the swarm
C:\> docker swarm join-token worker

# Get only the join-token needed to join a worker node to the swarm
C:\> docker swarm join-token worker -q
```

### Adding managers to a swarm
Additional manager nodes can be added to a swarm cluster with the following command:

```none
C:\> docker swarm join --token <MANAGERJOINTOKEN> <MANAGERIPADDRESS>
```

Again, <MANAGERIPADDRESS> is the local IP address of a swarm manager node. The join token, <MANAGERJOINTOKEN>, is a *manager* join-token for the swarm, which can be obtained by running one of the following commands from an existing manager node:

```none
# Get the full command required to join a **manager** node to the swarm
C:\> docker swarm join-token manager

# Get only the join-token needed to join a =**manager** node to the swarm
C:\> docker swarm join-token manager -q
```

## Creating an overlay network

Once a swarm cluster has been configured, overlay networks can be created on the swarm. An overlay network can be created by running the following command from a swarm manager node:

```none
# Create an overlay network 
C:\> docker network create --driver=overlay <NETWORKNAME>
```

Here, <NETWORKNAME> is the name you'd like to give to your network.

## Deploying services to a swarm
Once an overlay network has been created, services can be created and attached to the network. A network is created with the following syntax:

```none
# Deploy a service to the swarm
C:\> docker service create --name=<SERVICENAME> --endpoint-mode dnsrr --network=<NETWORKNAME> <CONTAINERIMAGE> [COMMAND] [ARGS…]
```

Here, <SERVICENAME> is the name you'd like to give to the service--this is the name you will use to reference the service via service discovery (which uses Docker's native DNS server). <NETWORKNAME> is the name of the network that you would like to connect this service to (for example, "myOverlayNet"). <CONTAINERIMAGE> is the name of the container image that will defined the service.

> **Note:** The second argument to this command, `--endpoint-mode dnsrr`, is required to specify to the Docker engine that the DNS Round Robin policy will be used to balance network traffic across service container endpoints. Currently, DNS Round-Robin is the only load balancing strategy supported on Windows.[Routing mesh](https://docs.docker.com/engine/swarm/ingress/) for Windows docker hosts is not yet supported, but will be coming soon. Users seeking an alternative load balancing strategy today can setup an external load balancer (e.g. NGINX) and use Swarm’s [publish-port mode](https://docs.docker.com/engine/reference/commandline/service_create/#/publish-service-ports-externally-to-the-swarm--p---publish) to expose container host ports over which to load balanc

## Scaling a service
Once a service is deployed to a swarm cluster, the container instances composing that service are deployed across the cluster. By default, the number of container instances backing a service—the number of “replicas,” or “tasks” for a service—is one. However, a service can be created with multiple tasks using the `--replicas` option to the `docker service create` command, or by scaling the service after it has been created.

Service scalability is a key benefit offered by Docker Swarm, and it, too, can be leveraged with a single Docker command:

```none
C:\> docker service scale <SERVICENAME>=<REPLICAS>
```

Here, <SERVICENAME> is the name of the service being scaled, and <REPLICAS> is the number of tasks, or container instances, to which the service is being scaled.

## Viewing the swarm state

There are several useful commands for viewing the state of a swarm and the services running on the swarm.

### List swarm nodes
Use the following command to see a list of the nodes currently joined to a swarm, including informaiton on the state of each node. This command must be run from a **manager node**.

```none
C:\ docker node ls
```

In the output of this command, you will notice one of the nodes marked with an asterisk (*); the asterisk simply indicates the current node--the node from which the `docker node ls` command was run.

### List networks
Use the following command to see a list of the networks that exist on a given node. To see overlay networks, this command must be run from a **manager node** running in swarm mode.

```none
C:\ docker network ls
```

### List services
Use the following command to see a list of the services currently running on a swarm, including information on their state.

```none
C:\ docker service ls
```

### List the container instances that define a service
Use the following command to see details on the container instances running for a given service. The output for this command includes the IDs and nodes upon which each container is running, as well as infromation on the state of the containers.  

```none
C:\ docker service ps <SERVICENAME>
```

## Limitations
Currently, swarm mode on Windows has the following limitations:
- Data-plan encryption not supported (i.e. container-container traffic using the `--opt encrypted` option)
- [Routing mesh](https://docs.docker.com/engine/swarm/ingress/) for Windows docker hosts is not yet supported, but will be coming soon. Users seeking an alternative load balancing strategy today can setup an external load balancer (e.g. NGINX) and use Swarm’s [publish-port mode](https://docs.docker.com/engine/reference/commandline/service_create/#/publish-service-ports-externally-to-the-swarm--p---publish) to expose container host ports over which to load balance.  


